{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Exploratory Data Analysis and Data Preprocessing\n",
    "## Intelligent Complaint Analysis for Financial Services\n",
    "\n",
    "**Objective:** Understand the structure, content, and quality of the complaint data and prepare it for the RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Set style for visualizations\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full CFPB complaint dataset\n",
    "data_path = Path('../data/raw/complaints.csv')\n",
    "print(f\"Loading data from: {data_path}\")\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(data_path, low_memory=False)\n",
    "\n",
    "print(f\"\\nDataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and missing values\n",
    "print(\"Data Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Percentage': missing_percentage\n",
    "}).sort_values('Percentage', ascending=False)\n",
    "\n",
    "print(\"Missing Values Analysis:\")\n",
    "print(missing_df[missing_df['Missing Count'] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Product Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze distribution of complaints across products\n",
    "print(\"Product Distribution:\")\n",
    "product_counts = df['Product'].value_counts()\n",
    "print(product_counts)\n",
    "\n",
    "# Visualize product distribution\n",
    "plt.figure(figsize=(14, 6))\n",
    "product_counts.head(15).plot(kind='barh', color='steelblue')\n",
    "plt.title('Top 15 Products by Complaint Count', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Number of Complaints', fontsize=12)\n",
    "plt.ylabel('Product', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Narrative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the narrative column (it might be named differently)\n",
    "narrative_columns = [col for col in df.columns if 'narrative' in col.lower() or 'complaint' in col.lower()]\n",
    "print(f\"Potential narrative columns: {narrative_columns}\")\n",
    "\n",
    "# Assuming the column is 'Consumer complaint narrative'\n",
    "narrative_col = 'Consumer complaint narrative' if 'Consumer complaint narrative' in df.columns else narrative_columns[0]\n",
    "print(f\"\\nUsing column: {narrative_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count complaints with and without narratives\n",
    "narratives_present = df[narrative_col].notna().sum()\n",
    "narratives_missing = df[narrative_col].isna().sum()\n",
    "\n",
    "print(f\"Complaints WITH narratives: {narratives_present:,} ({narratives_present/len(df)*100:.2f}%)\")\n",
    "print(f\"Complaints WITHOUT narratives: {narratives_missing:,} ({narratives_missing/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie([narratives_present, narratives_missing], \n",
    "        labels=['With Narrative', 'Without Narrative'],\n",
    "        autopct='%1.1f%%',\n",
    "        colors=['#2ecc71', '#e74c3c'],\n",
    "        startangle=90)\n",
    "plt.title('Distribution of Complaints by Narrative Availability', fontsize=14, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate word count for narratives\n",
    "df['narrative_word_count'] = df[narrative_col].fillna('').apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Filter only rows with narratives for analysis\n",
    "df_with_narratives = df[df[narrative_col].notna()].copy()\n",
    "\n",
    "print(\"Narrative Length Statistics (word count):\")\n",
    "print(df_with_narratives['narrative_word_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize narrative length distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df_with_narratives['narrative_word_count'], bins=50, color='skyblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Word Count', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('Distribution of Narrative Lengths', fontsize=14, fontweight='bold')\n",
    "axes[0].axvline(df_with_narratives['narrative_word_count'].median(), color='red', linestyle='--', label='Median')\n",
    "axes[0].legend()\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df_with_narratives['narrative_word_count'], vert=True)\n",
    "axes[1].set_ylabel('Word Count', fontsize=12)\n",
    "axes[1].set_title('Box Plot of Narrative Lengths', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify very short and very long narratives\n",
    "very_short = df_with_narratives[df_with_narratives['narrative_word_count'] < 10]\n",
    "very_long = df_with_narratives[df_with_narratives['narrative_word_count'] > 500]\n",
    "\n",
    "print(f\"Very short narratives (<10 words): {len(very_short):,}\")\n",
    "print(f\"Very long narratives (>500 words): {len(very_long):,}\")\n",
    "\n",
    "# Sample short narrative\n",
    "if len(very_short) > 0:\n",
    "    print(\"\\nExample of a very short narrative:\")\n",
    "    print(very_short[narrative_col].iloc[0])\n",
    "\n",
    "# Sample long narrative\n",
    "if len(very_long) > 0:\n",
    "    print(\"\\nExample of a very long narrative (first 500 chars):\")\n",
    "    print(very_long[narrative_col].iloc[0][:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Filter Dataset for Target Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target products\n",
    "target_products = [\n",
    "    'Credit card',\n",
    "    'Credit card or prepaid card',\n",
    "    'Personal loan',\n",
    "    'Savings account',\n",
    "    'Money transfer',\n",
    "    'Money transfers'\n",
    "]\n",
    "\n",
    "# Check exact product names in the dataset\n",
    "print(\"All unique products in dataset:\")\n",
    "all_products = df['Product'].unique()\n",
    "for product in sorted(all_products):\n",
    "    print(f\"  - {product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for target products (case-insensitive partial matching)\n",
    "def matches_target_product(product):\n",
    "    if pd.isna(product):\n",
    "        return False\n",
    "    product_lower = str(product).lower()\n",
    "    return any([\n",
    "        'credit card' in product_lower,\n",
    "        'personal loan' in product_lower,\n",
    "        'savings account' in product_lower,\n",
    "        'money transfer' in product_lower\n",
    "    ])\n",
    "\n",
    "df_filtered = df[df['Product'].apply(matches_target_product)].copy()\n",
    "\n",
    "print(f\"\\nOriginal dataset size: {len(df):,}\")\n",
    "print(f\"After product filtering: {len(df_filtered):,}\")\n",
    "print(f\"Reduction: {len(df) - len(df_filtered):,} rows ({(len(df) - len(df_filtered))/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove records with empty narratives\n",
    "df_filtered = df_filtered[df_filtered[narrative_col].notna()].copy()\n",
    "\n",
    "print(f\"After removing empty narratives: {len(df_filtered):,}\")\n",
    "\n",
    "# Show distribution of filtered products\n",
    "print(\"\\nFiltered Product Distribution:\")\n",
    "print(df_filtered['Product'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize filtered product distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "df_filtered['Product'].value_counts().plot(kind='bar', color='coral')\n",
    "plt.title('Complaint Distribution for Target Products', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Product', fontsize=12)\n",
    "plt.ylabel('Number of Complaints', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Text Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean complaint narrative text.\n",
    "    - Convert to lowercase\n",
    "    - Remove special characters (keep alphanumeric and basic punctuation)\n",
    "    - Remove extra whitespace\n",
    "    - Remove common boilerplate phrases\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to string and lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove common boilerplate phrases\n",
    "    boilerplate_patterns = [\n",
    "        r'i am writing to file a complaint',\n",
    "        r'i would like to file a complaint',\n",
    "        r'this is a complaint about',\n",
    "        r'xxxx',  # Common redaction marker\n",
    "    ]\n",
    "    for pattern in boilerplate_patterns:\n",
    "        text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    \n",
    "    # Remove email addresses\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Keep only alphanumeric characters and basic punctuation\n",
    "    text = re.sub(r'[^a-z0-9\\s.,!?;:\\-\\'\"()]', ' ', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Test the cleaning function\n",
    "sample_text = df_filtered[narrative_col].iloc[0]\n",
    "print(\"Original text (first 300 chars):\")\n",
    "print(sample_text[:300])\n",
    "print(\"\\nCleaned text (first 300 chars):\")\n",
    "print(clean_text(sample_text)[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning to all narratives\n",
    "print(\"Cleaning narratives...\")\n",
    "df_filtered['cleaned_narrative'] = df_filtered[narrative_col].apply(clean_text)\n",
    "\n",
    "# Remove any rows where cleaned narrative is empty\n",
    "df_filtered = df_filtered[df_filtered['cleaned_narrative'].str.len() > 0].copy()\n",
    "\n",
    "print(f\"Final dataset size after cleaning: {len(df_filtered):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cleaned narrative statistics\n",
    "df_filtered['cleaned_word_count'] = df_filtered['cleaned_narrative'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print(\"Cleaned Narrative Statistics:\")\n",
    "print(df_filtered['cleaned_word_count'].describe())\n",
    "\n",
    "# Compare before and after cleaning\n",
    "comparison = pd.DataFrame({\n",
    "    'Original': df_filtered['narrative_word_count'].describe(),\n",
    "    'Cleaned': df_filtered['cleaned_word_count'].describe()\n",
    "})\n",
    "print(\"\\nComparison of Word Counts:\")\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Additional Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze issues and sub-issues if available\n",
    "if 'Issue' in df_filtered.columns:\n",
    "    print(\"Top 10 Issues:\")\n",
    "    print(df_filtered['Issue'].value_counts().head(10))\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    df_filtered['Issue'].value_counts().head(10).plot(kind='barh', color='teal')\n",
    "    plt.title('Top 10 Complaint Issues', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Count', fontsize=12)\n",
    "    plt.ylabel('Issue', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal analysis if date column exists\n",
    "date_columns = [col for col in df_filtered.columns if 'date' in col.lower()]\n",
    "if date_columns:\n",
    "    date_col = date_columns[0]\n",
    "    print(f\"Using date column: {date_col}\")\n",
    "    \n",
    "    df_filtered[date_col] = pd.to_datetime(df_filtered[date_col], errors='coerce')\n",
    "    df_filtered['year'] = df_filtered[date_col].dt.year\n",
    "    df_filtered['month'] = df_filtered[date_col].dt.month\n",
    "    \n",
    "    # Complaints over time\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    df_filtered.groupby('year').size().plot(kind='line', marker='o', color='purple', linewidth=2)\n",
    "    plt.title('Complaints Over Time', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Year', fontsize=12)\n",
    "    plt.ylabel('Number of Complaints', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Filtered and Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns for the processed dataset\n",
    "columns_to_keep = [\n",
    "    'Product',\n",
    "    'Issue',\n",
    "    'Sub-issue',\n",
    "    'Company',\n",
    "    'State',\n",
    "    'Date received',\n",
    "    narrative_col,\n",
    "    'cleaned_narrative'\n",
    "]\n",
    "\n",
    "# Filter to only existing columns\n",
    "columns_to_keep = [col for col in columns_to_keep if col in df_filtered.columns]\n",
    "\n",
    "df_final = df_filtered[columns_to_keep].copy()\n",
    "\n",
    "# Add a unique complaint ID if not present\n",
    "if 'Complaint ID' not in df_final.columns:\n",
    "    df_final.insert(0, 'complaint_id', range(1, len(df_final) + 1))\n",
    "else:\n",
    "    df_final.rename(columns={'Complaint ID': 'complaint_id'}, inplace=True)\n",
    "\n",
    "print(f\"Final dataset shape: {df_final.shape}\")\n",
    "print(f\"Columns: {df_final.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to processed data folder\n",
    "output_path = Path('../data/processed/filtered_complaints.csv')\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_final.to_csv(output_path, index=False)\n",
    "print(f\"\\nâœ… Filtered and cleaned dataset saved to: {output_path}\")\n",
    "print(f\"Total records: {len(df_final):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary of Findings\n",
    "\n",
    "### Key Findings from EDA:\n",
    "\n",
    "1. **Dataset Overview:**\n",
    "   - Original dataset contained [X] complaints\n",
    "   - After filtering for target products and removing empty narratives: [Y] complaints\n",
    "\n",
    "2. **Product Distribution:**\n",
    "   - Credit cards account for the majority of complaints\n",
    "   - [Add specific insights from your analysis]\n",
    "\n",
    "3. **Narrative Characteristics:**\n",
    "   - Average narrative length: [X] words\n",
    "   - Median narrative length: [Y] words\n",
    "   - Range: [min] to [max] words\n",
    "   - Some narratives are very short (<10 words) and may have limited context\n",
    "   - Some narratives are very long (>500 words) and will benefit from chunking\n",
    "\n",
    "4. **Data Quality:**\n",
    "   - [X]% of complaints had narratives\n",
    "   - Text cleaning removed boilerplate phrases and special characters\n",
    "   - All target product categories are well-represented\n",
    "\n",
    "### Next Steps:\n",
    "- Proceed to Task 2: Text Chunking and Vector Store Indexing\n",
    "- Use the cleaned narratives for embedding generation\n",
    "- Consider chunk size based on narrative length distribution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
